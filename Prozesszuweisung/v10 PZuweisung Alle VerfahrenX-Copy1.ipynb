{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce540ba-51d7-434c-901f-bc8de49ff893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 1 - Pakete\n",
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56efa464-550d-40ec-9b2f-0b153d772968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prozess</th>\n",
       "      <th>Laufzeit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>168.057070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>154.393829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>102.313037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>100.970770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>92.287095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>19185</td>\n",
       "      <td>0.006664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>19186</td>\n",
       "      <td>0.014815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>19187</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>19188</td>\n",
       "      <td>0.007734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>19189</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1900 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prozess    Laufzeit\n",
       "0       10000  168.057070\n",
       "1       10001  154.393829\n",
       "2       10002  102.313037\n",
       "3       10003  100.970770\n",
       "4       10004   92.287095\n",
       "...       ...         ...\n",
       "1895    19185    0.006664\n",
       "1896    19186    0.014815\n",
       "1897    19187    0.025000\n",
       "1898    19188    0.007734\n",
       "1899    19189    0.012500\n",
       "\n",
       "[1900 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Zelle 2 - Input: Excel einlesen und Prozessdaten erzeugen\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "#  Datei-Pfad angeben (bitte anpassen)\n",
    "path = r\"C:/Users/.../Masterarbeit/Python/\"\n",
    "#excel_path = r\"C:/Users/Pablo/Documents/Uni/Masterarbeit/Python/Prozesse.xlsx\"\n",
    "input_folger = r\"Kostenmodell x10/\"\n",
    "excel_file = r\"Prozesslaufzeiten und Konfig x10.xlsx\"\n",
    "excel_path = path + input_folger + excel_file\n",
    "\n",
    "#  Excel einlesen\n",
    "#df_prozesse_raw = pd.read_excel(excel_path, sheet_name=\"Monatslaufzeiten\")\n",
    "df_prozesse_raw = pd.read_excel(excel_path, sheet_name=\"Jahreslaufzeiten\")\n",
    "\n",
    "\n",
    "df_prozesse_raw = df_prozesse_raw.dropna(subset=[\"xProzess_ID\"])\n",
    "df_prozesse_raw[\"xProzess_ID\"] = df_prozesse_raw[\"xProzess_ID\"].astype(int)\n",
    "\n",
    "df_prozesse_raw = df_prozesse_raw.rename(columns={\"Laufzeit\": \"Laufzeit\"})\n",
    "df_prozesse_raw = df_prozesse_raw.rename(columns={\"xProzess_ID\": \"Prozess\"})\n",
    "\n",
    "df_prozesse_raw = df_prozesse_raw[[\"Prozess\", \"Month\", \"Laufzeit\"]]\n",
    "\n",
    "df_prozesse = (df_prozesse_raw.groupby(\"Prozess\", as_index=False).agg(Laufzeit=(\"Laufzeit\", \"mean\")))\n",
    "#df_prozesse = df_prozesse_raw[[\"Prozess\", \"Laufzeit\"]]\n",
    "\n",
    "display(df_prozesse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e519adbd-24eb-423f-9ffd-faa1b368ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Zelle 3 - Config\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Maximale Laufzeit pro VDI / Bot pro Tag (Stunden)\n",
    "MAX_HOURS_PER_DAY = 20\n",
    "\n",
    "# Pool-GrÃ¶ÃŸen (Anzahl Prozesse, die sich eine VDI teilen dÃ¼rfen)\n",
    "POOL_SIZES = [0, 1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 32, 64, 128, 256, 512, 1000, 5000]\n",
    "\n",
    "# Exponentielle Basen fÃ¼r Score-Greedy\n",
    "EXP_BASES = [1.1, 1.2, 1.25, 2.0]\n",
    "\n",
    "# Output-Pfad fÃ¼r Konstellationen\n",
    "OUTPUT_FOLDER = Path(path + input_folger + \"JSON\")\n",
    "\n",
    "# Steuerung: welche Verfahren sollen ausgefÃ¼hrt werden\n",
    "ASSIGNMENT_METHODS = [\n",
    "    \"greedy\",\n",
    "    \"score_greedy\",\n",
    "    \"preseeding_best_fit\",\n",
    "    \"pairing_top90\",\n",
    "]\n",
    "\n",
    "\n",
    "# Optional: 0er-Pool Ã¼berspringen\n",
    "SKIP_POOL_SIZE_ZERO = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5266f1f3-3526-417f-a876-635502c3ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_prozesse.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c2f64a-8faf-4df5-87f7-6d385446a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Zelle 4 - Zuweisungsverfahren\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "def assign_greedy(df: pd.DataFrame, pool_size: int, max_hours_per_day: float) -> dict:\n",
    "    \"\"\"\n",
    "    Greedy-Zuweisung: Prozesse werden nach Laufzeit sortiert\n",
    "    und sequenziell zu Gruppen zusammengefasst.\n",
    "    \"\"\"\n",
    "\n",
    "    pool_max_hours_per_day = max_hours_per_day * pool_size\n",
    "\n",
    "    # Sonderfall: pool_size == 0 â†’ alle Prozesse solo\n",
    "    if pool_size == 0:\n",
    "        konstellation = [[int(pid)] for pid in df[\"Prozess\"]]\n",
    "        return {\n",
    "            \"verfahren\": \"greedy\",\n",
    "            \"pool_size\": pool_size,\n",
    "            \"titel\": f\"Greedy_Pool{pool_size}\",\n",
    "            \"notiz\": \"PoolgrÃ¶ÃŸe 0: alle Prozesse einzeln.\",\n",
    "            \"konstellation\": konstellation,\n",
    "        }\n",
    "\n",
    "    # Prozesse trennen\n",
    "    solo_df = df[df[\"Laufzeit\"] > pool_max_hours_per_day].copy()\n",
    "    pool_df = df[df[\"Laufzeit\"] <= pool_max_hours_per_day].copy()\n",
    "\n",
    "    # Sortierung fÃ¼r bessere Packung\n",
    "    pool_df = pool_df.sort_values(\"Laufzeit\", ascending=False)\n",
    "\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    current_hours = 0.0\n",
    "\n",
    "    for _, row in pool_df.iterrows():\n",
    "        runtime = row[\"Laufzeit\"]\n",
    "        process = int(row[\"Prozess\"])\n",
    "\n",
    "        if current_hours + runtime <= pool_max_hours_per_day:\n",
    "            current_group.append(process)\n",
    "            current_hours += runtime\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [process]\n",
    "            current_hours = runtime\n",
    "\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    konstellation = []\n",
    "    konstellation.extend(groups)\n",
    "\n",
    "    for _, row in solo_df.iterrows():\n",
    "        konstellation.append([int(row[\"Prozess\"])])\n",
    "\n",
    "    return {\n",
    "        \"verfahren\": \"greedy\",\n",
    "        \"pool_size\": pool_size,\n",
    "        \"titel\": f\"Greedy_Poolsize{pool_size}\",\n",
    "        \"notiz\": f\"Greedy-Zuweisung mit PoolgrÃ¶ÃŸe {pool_size}.\",\n",
    "        \"konstellation\": konstellation,\n",
    "    }\n",
    "\n",
    "\n",
    "def _assign_score_greedy_core(\n",
    "    df: pd.DataFrame,\n",
    "    pool_size: int,\n",
    "    max_hours_per_day: float,\n",
    "    exp_base: float,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Core-Funktion: Score-Greedy mit fester exponentieller Basis.\n",
    "    \"\"\"\n",
    "\n",
    "    pool_max_hours_per_day = max_hours_per_day * pool_size\n",
    "\n",
    "    if pool_size == 0:\n",
    "        konstellation = [[int(pid)] for pid in df[\"Prozess\"]]\n",
    "        return {\n",
    "            \"verfahren\": \"score_greedy\",\n",
    "            \"pool_size\": pool_size,\n",
    "            \"exp_base\": exp_base,\n",
    "            \"titel\": f\"ScoreGreedy_b{exp_base}_Poolsize{pool_size}\",\n",
    "            \"notiz\": \"PoolgrÃ¶ÃŸe 0: alle Prozesse einzeln.\",\n",
    "            \"konstellation\": konstellation,\n",
    "        }\n",
    "\n",
    "    solo_df = df[df[\"Laufzeit\"] > pool_max_hours_per_day].copy()\n",
    "    pool_df = df[df[\"Laufzeit\"] <= pool_max_hours_per_day].copy()\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    # ðŸ”¹ Solo-Prozesse initialisieren\n",
    "    for _, row in solo_df.iterrows():\n",
    "        groups.append({\n",
    "            \"prozesse\": [int(row[\"Prozess\"])],\n",
    "            \"hours\": float(row[\"Laufzeit\"]),\n",
    "        })\n",
    "\n",
    "    pool_df = pool_df.sort_values(\"Laufzeit\", ascending=False)\n",
    "\n",
    "    # ðŸ”¹ Score-Greedy-Zuweisung\n",
    "    for _, row in pool_df.iterrows():\n",
    "        runtime = float(row[\"Laufzeit\"])\n",
    "        process = int(row[\"Prozess\"])\n",
    "\n",
    "        best_group = None\n",
    "        best_score = None\n",
    "\n",
    "        for group in groups:\n",
    "            if group[\"hours\"] + runtime > pool_max_hours_per_day:\n",
    "                continue\n",
    "\n",
    "            n = len(group[\"prozesse\"])\n",
    "\n",
    "            try:\n",
    "                score = exp_base ** n\n",
    "            except OverflowError:\n",
    "                # Diese zu groÃŸen Gruppierungsoption ignorieren\n",
    "                continue\n",
    "\n",
    "            if best_score is None or score < best_score:\n",
    "                best_group = group\n",
    "                best_score = score\n",
    "\n",
    "        # ðŸ”¹ Zuweisung\n",
    "        if best_group is not None:\n",
    "            best_group[\"prozesse\"].append(process)\n",
    "            best_group[\"hours\"] += runtime\n",
    "        else:\n",
    "            groups.append({\n",
    "                \"prozesse\": [process],\n",
    "                \"hours\": runtime,\n",
    "            })\n",
    "\n",
    "    konstellation = [g[\"prozesse\"] for g in groups]\n",
    "\n",
    "    return {\n",
    "        \"verfahren\": \"score_greedy\",\n",
    "        \"pool_size\": pool_size,\n",
    "        \"exp_base\": exp_base,\n",
    "        \"titel\": f\"ScoreGreedy_b{exp_base}_Poolsize{pool_size}\",\n",
    "        \"notiz\": (\n",
    "            f\"Score-Greedy mit exponentiellen Grenzkosten \"\n",
    "            f\"(Basis={exp_base}, PoolgrÃ¶ÃŸe={pool_size}).\"\n",
    "        ),\n",
    "        \"konstellation\": konstellation,\n",
    "    }\n",
    "\n",
    "\n",
    "def assign_score_greedy(\n",
    "    df: pd.DataFrame,\n",
    "    pool_size: int,\n",
    "    max_hours_per_day: float,\n",
    "    exp_bases: list[float],\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Wrapper: fÃ¼hrt Score-Greedy fÃ¼r mehrere exponentielle Basen aus.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for exp_base in exp_bases:\n",
    "        result = _assign_score_greedy_core(\n",
    "            df=df,\n",
    "            pool_size=pool_size,\n",
    "            max_hours_per_day=max_hours_per_day,\n",
    "            exp_base=exp_base,\n",
    "        )\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def assign_preseeding_best_fit(\n",
    "    df: pd.DataFrame,\n",
    "    pool_size: int,\n",
    "    max_hours_per_day: float,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Pre-Seeding Best-Fit:\n",
    "    - Prozesse, die nicht pool-fÃ¤hig sind, starten eigene Pools\n",
    "    - restliche Prozesse werden per Best-Fit (min. RestkapazitÃ¤t) zugewiesen\n",
    "    \"\"\"\n",
    "\n",
    "    pool_max_hours_per_day = max_hours_per_day * pool_size\n",
    "\n",
    "    # Sonderfall: pool_size == 0 â†’ alles solo\n",
    "    if pool_size == 0:\n",
    "        konstellation = [[int(pid)] for pid in df[\"Prozess\"]]\n",
    "        return {\n",
    "            \"verfahren\": \"preseeding_best_fit\",\n",
    "            \"pool_size\": pool_size,\n",
    "            \"titel\": f\"PreSeedingBestFit_Poolsize{pool_size}\",\n",
    "            \"notiz\": \"PoolgrÃ¶ÃŸe 0: alle Prozesse einzeln.\",\n",
    "            \"konstellation\": konstellation,\n",
    "        }\n",
    "\n",
    "    # Prozesse trennen\n",
    "    solo_df = df[df[\"Laufzeit\"] > pool_max_hours_per_day].copy()\n",
    "    pool_df = df[df[\"Laufzeit\"] <= pool_max_hours_per_day].copy()\n",
    "\n",
    "    pools = []\n",
    "\n",
    "    # ðŸ”¹ Pre-Seeding mit Solo-Prozessen\n",
    "    for _, row in solo_df.iterrows():\n",
    "        pools.append({\n",
    "            \"prozesse\": [int(row[\"Prozess\"])],\n",
    "            \"hours\": float(row[\"Laufzeit\"]),\n",
    "        })\n",
    "\n",
    "    # ðŸ”¹ Lange Prozesse zuerst (klassisch fÃ¼r Best-Fit)\n",
    "    pool_df = pool_df.sort_values(\"Laufzeit\", ascending=False)\n",
    "\n",
    "    # ðŸ”¹ Best-Fit-Zuweisung\n",
    "    for _, row in pool_df.iterrows():\n",
    "        runtime = float(row[\"Laufzeit\"])\n",
    "        process = int(row[\"Prozess\"])\n",
    "\n",
    "        best_pool = None\n",
    "        best_remaining_capacity = None\n",
    "\n",
    "        for pool in pools:\n",
    "            remaining_capacity = pool_max_hours_per_day - pool[\"hours\"]\n",
    "\n",
    "            if remaining_capacity >= runtime:\n",
    "                if (\n",
    "                    best_remaining_capacity is None\n",
    "                    or remaining_capacity < best_remaining_capacity\n",
    "                ):\n",
    "                    best_pool = pool\n",
    "                    best_remaining_capacity = remaining_capacity\n",
    "\n",
    "        if best_pool is not None:\n",
    "            best_pool[\"prozesse\"].append(process)\n",
    "            best_pool[\"hours\"] += runtime\n",
    "        else:\n",
    "            pools.append({\n",
    "                \"prozesse\": [process],\n",
    "                \"hours\": runtime,\n",
    "            })\n",
    "\n",
    "    konstellation = [pool[\"prozesse\"] for pool in pools]\n",
    "\n",
    "    return {\n",
    "        \"verfahren\": \"preseeding_best_fit\",\n",
    "        \"pool_size\": pool_size,\n",
    "        \"titel\": f\"PreSeedingBestFit_Poolsize{pool_size}\",\n",
    "        \"notiz\": (\n",
    "            \"Best-Fit-Verfahren mit Pre-Seeding: \"\n",
    "            \"nicht pool-fÃ¤hige Prozesse starten eigene Pools.\"\n",
    "        ),\n",
    "        \"konstellation\": konstellation,\n",
    "    }\n",
    "\n",
    "\n",
    "def assign_pairing_top90(\n",
    "    df: pd.DataFrame,\n",
    "    pool_size: int,\n",
    "    max_hours_per_day: float,\n",
    "    top_exclude_ratio: float = 0.10,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Pairing-Verfahren:\n",
    "    - Top X% der Prozesse (nach Laufzeit) werden ausgeschlossen (solo)\n",
    "    - Restliche Prozesse werden paarweise gruppiert\n",
    "    - Maximal `pool_size` Paare\n",
    "    \"\"\"\n",
    "\n",
    "    # Sonderfall\n",
    "    if pool_size == 0:\n",
    "        konstellation = [[int(pid)] for pid in df[\"Prozess\"]]\n",
    "        return {\n",
    "            \"verfahren\": \"pairing_top90\",\n",
    "            \"pool_size\": pool_size,\n",
    "            \"titel\": f\"PairingTop90_Poolsize{pool_size}\",\n",
    "            \"notiz\": \"PoolgrÃ¶ÃŸe 0: alle Prozesse einzeln.\",\n",
    "            \"konstellation\": konstellation,\n",
    "        }\n",
    "\n",
    "    # ðŸ”¹ Sortieren nach Laufzeit (absteigend)\n",
    "    df_sorted = df.sort_values(\"Laufzeit\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    n_total = len(df_sorted)\n",
    "    n_exclude = int(math.ceil(n_total * top_exclude_ratio))\n",
    "\n",
    "    # ðŸ”¹ Top 10 % â†’ solo\n",
    "    excluded_df = df_sorted.iloc[:n_exclude]\n",
    "    candidate_df = df_sorted.iloc[n_exclude:]\n",
    "\n",
    "    konstellation = []\n",
    "\n",
    "    # Solo-Gruppen (Top 10 %)\n",
    "    for _, row in excluded_df.iterrows():\n",
    "        konstellation.append([int(row[\"Prozess\"])])\n",
    "\n",
    "    # ðŸ”¹ Pairing-Kandidaten sortieren (aufsteigend fÃ¼r Two-Pointer)\n",
    "    candidates = candidate_df.sort_values(\"Laufzeit\").reset_index(drop=True)\n",
    "\n",
    "    left = 0\n",
    "    right = len(candidates) - 1\n",
    "    pairs_formed = 0\n",
    "\n",
    "    used = set()\n",
    "\n",
    "    while left < right and pairs_formed < pool_size:\n",
    "        p_left = candidates.iloc[left]\n",
    "        p_right = candidates.iloc[right]\n",
    "\n",
    "        runtime_sum = p_left[\"Laufzeit\"] + p_right[\"Laufzeit\"]\n",
    "\n",
    "        if runtime_sum <= max_hours_per_day:\n",
    "            konstellation.append([\n",
    "                int(p_left[\"Prozess\"]),\n",
    "                int(p_right[\"Prozess\"]),\n",
    "            ])\n",
    "            pairs_formed += 1\n",
    "            left += 1\n",
    "            right -= 1\n",
    "        else:\n",
    "            # LÃ¤ngster Prozess passt mit niemandem â†’ solo\n",
    "            konstellation.append([int(p_right[\"Prozess\"])])\n",
    "            right -= 1\n",
    "\n",
    "    # ðŸ”¹ Ãœbrige Kandidaten â†’ solo\n",
    "    for i in range(left, right + 1):\n",
    "        konstellation.append([int(candidates.iloc[i][\"Prozess\"])])\n",
    "\n",
    "    return {\n",
    "        \"verfahren\": \"pairing_top90\",\n",
    "        \"pool_size\": pool_size,\n",
    "        \"titel\": f\"PairingTop90_Poolsize{pool_size}\",\n",
    "        \"notiz\": (\n",
    "            f\"Paarungsbasiertes Verfahren: Top {int(top_exclude_ratio*100)}% \"\n",
    "            \"der Prozesse solo, Rest paarweise gruppiert \"\n",
    "            f\"(max. {pool_size} Paare).\"\n",
    "        ),\n",
    "        \"konstellation\": konstellation,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "ASSIGNMENT_FUNCTIONS = {\n",
    "    \"greedy\": assign_greedy,\n",
    "    \"score_greedy\": assign_score_greedy,\n",
    "    \"preseeding_best_fit\": assign_preseeding_best_fit,\n",
    "    \"pairing_top90\": assign_pairing_top90,\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9625f840-c9d7-46ba-b4fe-45639bba729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Exportiert: konstellation_greedy_poolsize1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize1_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize1_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize1_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize1_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize1.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize1.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize2_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize2_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize2_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize2_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize2.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize2.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize4.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize4_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize4_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize4_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize4_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize4.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize4.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize6.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize6_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize6_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize6_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize6_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize6.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize6.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize8.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize8_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize8_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize8_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize8_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize8.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize8.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize10.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize10_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize10_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize10_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize10_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize10.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize10.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize12.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize12_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize12_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize12_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize12_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize12.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize12.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize14.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize14_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize14_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize14_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize14_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize14.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize14.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize16.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize16_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize16_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize16_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize16_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize16.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize16.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize18.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize18_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize18_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize18_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize18_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize18.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize18.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize20.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize20_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize20_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize20_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize20_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize20.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize20.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize22.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize22_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize22_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize22_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize22_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize22.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize22.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize24.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize24_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize24_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize24_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize24_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize24.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize24.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize32.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize32_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize32_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize32_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize32_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize32.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize32.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize64.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize64_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize64_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize64_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize64_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize64.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize64.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize128.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize128_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize128_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize128_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize128_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize128.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize128.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize256.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize256_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize256_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize256_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize256_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize256.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize256.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize512.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize512_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize512_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize512_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize512_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize512.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize512.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize1000.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize1000_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize1000_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize1000_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize1000_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize1000.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize1000.json\n",
      "âœ” Exportiert: konstellation_greedy_poolsize5000.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize5000_b1.1.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize5000_b1.2.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize5000_b1.25.json\n",
      "âœ” Exportiert: konstellation_score_greedy_poolsize5000_b2.0.json\n",
      "âœ” Exportiert: konstellation_preseeding_best_fit_poolsize5000.json\n",
      "âœ” Exportiert: konstellation_pairing_top90_poolsize5000.json\n",
      "C:\\Users\\Hippo\\Documents\\Uni\\Masterarbeit\\Python\\Kostenmodell v10\\JSON\\konstellation_pairing_top90_poolsize5000.json\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Zelle 5 - Orchestrierung & Export\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "export_index = []  # Ãœberblick Ã¼ber alle erzeugten Konstellationen\n",
    "\n",
    "for pool_size in POOL_SIZES:\n",
    "\n",
    "    if SKIP_POOL_SIZE_ZERO and pool_size == 0:\n",
    "        continue\n",
    "\n",
    "    for method_name in ASSIGNMENT_METHODS:\n",
    "\n",
    "        assign_fn = ASSIGNMENT_FUNCTIONS[method_name]\n",
    "\n",
    "        # Verfahren ausfÃ¼hren\n",
    "        result = assign_fn(\n",
    "            df=df_prozesse,\n",
    "            pool_size=pool_size,\n",
    "            max_hours_per_day=MAX_HOURS_PER_DAY,\n",
    "            **(\n",
    "                {\"exp_bases\": EXP_BASES}\n",
    "                if method_name == \"score_greedy\"\n",
    "                else {}\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Einheitliche Behandlung (einzelnes Dict oder Liste von Dicts)\n",
    "        results = result if isinstance(result, list) else [result]\n",
    "\n",
    "        for r in results:\n",
    "\n",
    "            exp_base = r.get(\"exp_base\")  # None bei Greedy\n",
    "\n",
    "            # JSON-Dateiname (inkl. Basis, falls vorhanden)\n",
    "            json_filename = (\n",
    "                f\"konstellation_{r['verfahren']}\"\n",
    "                f\"_poolsize{pool_size}\"\n",
    "                + (f\"_b{exp_base}\" if exp_base is not None else \"\")\n",
    "                + \".json\"\n",
    "            )\n",
    "\n",
    "            json_path = OUTPUT_FOLDER / json_filename\n",
    "\n",
    "            # JSON schreiben\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(r, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "            print(f\"âœ” Exportiert: {json_filename}\")\n",
    "\n",
    "            # Index-Eintrag\n",
    "            export_index.append({\n",
    "                \"verfahren\": r[\"verfahren\"],\n",
    "                \"pool_size\": pool_size,\n",
    "                \"exp_base\": exp_base,\n",
    "                \"titel\": r[\"titel\"],\n",
    "                \"datei\": json_filename,\n",
    "                \"anzahl_gruppen\": len(r[\"konstellation\"]),\n",
    "            })\n",
    "\n",
    "print(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95c53fe-b746-47b2-aa4e-7efccfe44da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Zusammenfassung der Extremwerte:\n",
      "\n",
      "  Anzahl aller Konstellationen : 140\n",
      "\n",
      "ðŸ”º Pool-reichstes Ergebnis:\n",
      "  Verfahren        : pairing_top90\n",
      "  Pool-GrÃ¶ÃŸe       : 1\n",
      "  Exponentielle Basis : None\n",
      "  Anzahl Pools     : 1899 (vgl. Anzahl Prozesse: 1900)\n",
      "  Datei            : konstellation_pairing_top90_poolsize1.json\n",
      "\n",
      "ðŸ”» Pool-Ã¤rmstes Ergebnis:\n",
      "  Verfahren        : greedy\n",
      "  Pool-GrÃ¶ÃŸe       : 5000\n",
      "  Exponentielle Basis : None\n",
      "  Anzahl Pools     : 1\n",
      "  Datei            : konstellation_greedy_poolsize5000.json\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Zelle 6 - Zusammenfassung: Pool-reichstes & Pool-Ã¤rmstes Ergebnis\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "if export_index:\n",
    "\n",
    "    # Pool-reichstes Ergebnis (meiste Gruppen)\n",
    "    max_pools_result = max(export_index, key=lambda x: x[\"anzahl_gruppen\"])\n",
    "\n",
    "    # Pool-Ã¤rmstes Ergebnis (wenigste Gruppen)\n",
    "    min_pools_result = min(export_index, key=lambda x: x[\"anzahl_gruppen\"])\n",
    "\n",
    "    print(\"\\nðŸ“Š Zusammenfassung der Extremwerte:\\n\")\n",
    "    print(f\"  Anzahl aller Konstellationen : {len(export_index)}\\n\")\n",
    "\n",
    "    print(\"ðŸ”º Pool-reichstes Ergebnis:\")\n",
    "    print(f\"  Verfahren        : {max_pools_result['verfahren']}\")\n",
    "    print(f\"  Pool-GrÃ¶ÃŸe       : {max_pools_result['pool_size']}\")\n",
    "    print(f\"  Exponentielle Basis : {max_pools_result.get('exp_base')}\")\n",
    "    print(f\"  Anzahl Pools     : {max_pools_result['anzahl_gruppen']} (vgl. Anzahl Prozesse: {len(df)})\")\n",
    "    print(f\"  Datei            : {max_pools_result['datei']}\\n\")\n",
    "\n",
    "    print(\"ðŸ”» Pool-Ã¤rmstes Ergebnis:\")\n",
    "    print(f\"  Verfahren        : {min_pools_result['verfahren']}\")\n",
    "    print(f\"  Pool-GrÃ¶ÃŸe       : {min_pools_result['pool_size']}\")\n",
    "    print(f\"  Exponentielle Basis : {min_pools_result.get('exp_base')}\")\n",
    "    print(f\"  Anzahl Pools     : {min_pools_result['anzahl_gruppen']}\")\n",
    "    print(f\"  Datei            : {min_pools_result['datei']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf98885-7352-4e18-9340-9ad25a7e5850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
